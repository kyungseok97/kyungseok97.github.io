<html>
  <head>
    <meta charset="UTF-8">
    <style type="text/css">
      #title {text-align: center; font-family: arial;}
      #authors {text-align: center; font-style: italic; font-size: 19px; font-family: arial;}
      #abstract {text-align: center; font-family: arial;}
      #Audio-Samples {text-align: center; font-family: arial;}
      #Audio-Samples-detail {text-align: center; font-weight: normal; font-size: 17px; font-family: arial;}

      .container {width: 900px; margin: 30px auto;}
      .centered {position: relative;display: inline-block; padding: 1em;font-weight: normal;font-size: 17px;font-family: arial;}
      .sample {text-align: center; font-family: arial;}
      .container-sample1 {width: 1400px; margin: 5px auto;}
      .centered-sample1 {position: relative;display: inline-block;padding: 1em;font-weight: normal;font-size: 17px;font-family: arial;}
      .sample1 {font-style: italic; font-family: arial;}
      .grey {font-style: italic; font-size: 15px; font-family: arial;}
    </style>
  </head>

  <body>
    <h1 id="title"><br />Automated Emotional Voice Generator Using Voice Conversion and Data Sampler</h1>
    <p id="authors">Kyungseok Oh, Yongmin Kim, Jeongki Min, Junyeop Lee, Bonhwa Ku, and Hanseok Ko</p>

    <h2 id="abstract"><br /><br />Abstract</h2>
    <div class="container">
      <div class="centered">
	Public multi-speaker multi-emotion datasets have
	a limited number of speakers and therefore a limited number
	of styles that voice generation models can represent. In this
	paper, we propose a framework for generating diverse multi-
	speaker multi-emotion data using Emotional Voice Conversion
	(EVC) and a data sampler. Conventional EVC has difficulty in
	separating multiple speaker emotional styles because it acquires
	style features from a single style encoder. We proposed a novel
	speaker/emotion encoder, depending on whether or not it is
	associated with the identity of the speaker. Additionally, more
	effective speaker-style separation is performed through mutual
	information of the two encoders. To ensure the quality of data
	generated by EVC, we perform a data sampler process. The data
	sampler verifies the quality of the generated data through pMOS,
	speaker similarity, and emotion accuracy, and only samples that
	exceed the threshold are selected as data. We demonstrated
	the excellence of the proposed method through subjective and
	objective evaluation. The proposed framework using the EVC
	and data sampler demonstrated the feasibility of generating
	multi-speaker multi-emotion data
      </div>
    </div>

    <h3 class="sample"><br /><br />Overall EVC architecture and Data sampler</h3>
	<p align="center">
	  <img width="600" height="400" src="https://github.com/kyungseok97/kyungseok97.github.io/assets/160107291/8af49577-15ab-49cd-a99a-7a0d9d6cd2f7">
	</p>

	  
    <h3 class="sample"><br /><br />Comparison According to Size of Adaptation Data</h3>
    <div class="container-sample1">
      <div class="centered-sample1">
        <p class="sample1">Text: The style guide has been amended accordingly.</p>
        <table>
          <thead>
            <tr>
              <th> </th>
              <th>Grond Truth</th>
              <th>Full Data</th>
              <th>20min</th>
              <th>10min</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>SE-ATTS(24spk)*</strong></td>
              <td><audio controls="controls">  <source type="audio/wav" src="data/GT/spk136_F_0103.wav" />&lt;/source&gt; </audio></td>
              <td><audio controls="controls">  <source type="audio/wav" src="data/few_sample/model_A/full/spk136_F_0103.wav" />&lt;/source&gt; </audio></td>
              <td><audio controls="controls">  <source type="audio/wav" src="data/few_sample/model_A/20min/spk136_F_0103.wav" />&lt;/source&gt; </audio></td>
              <td><audio controls="controls">  <source type="audio/wav" src="data/few_sample/model_A/10min/spk136_F_0103.wav" />&lt;/source&gt; </audio></td>
            </tr>
            <tr>
              <td><strong>SE-ATTS(24spk)</strong></td>
              <td><audio controls="controls">  <source type="audio/wav" src="data/GT/spk136_F_0103.wav" />&lt;/source&gt; </audio></td>
              <td><audio controls="controls">  <source type="audio/wav" src="data/few_sample/model_B/full/spk136_F_0103.wav" />&lt;/source&gt; </audio></td>
              <td><audio controls="controls">  <source type="audio/wav" src="data/few_sample/model_B/20min/spk136_F_0103.wav" />&lt;/source&gt; </audio></td>
              <td><audio controls="controls">  <source type="audio/wav" src="data/few_sample/model_B/10min/spk136_F_0103.wav" />&lt;/source&gt; </audio></td>
            </tr>
          </tbody>
        </table>
        <p class="grey">* w/o style eqaulizer.</p>
      </div>
    </div>
  </body>
</html>
